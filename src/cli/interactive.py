from typing import Any

import questionary
from rich import print

from .config import ConfigManager
from .llm_providers import PROVIDER_CONFIGS, LLMProvider, get_provider_instance


class InteractiveSetup:
    """
    è´Ÿè´£MikuCastçš„äº¤äº’å¼è®¾ç½®æµç¨‹ã€‚
    ä¾èµ–äº ConfigManager å’Œ LLMProvider å·¥å‚å‡½æ•°ã€‚
    """

    def __init__(self, config_mgr: ConfigManager):
        self._config_mgr = config_mgr

    def run_setup(self):
        """
        å¼•å¯¼ç”¨æˆ·è¿›è¡Œäº¤äº’å¼é…ç½®ã€‚
        """
        print("ğŸ‘‹ Welcome to MikuCast CLI! Let's set up your LLM provider.")

        provider_choices = [
            # Use .capitalize() for a nicer display name (e.g., "Openai" -> "OpenAI")
            questionary.Choice(title=key.capitalize(), value=key)
            for key in PROVIDER_CONFIGS.keys()
        ]

        # 3. Add the special "Customize" option with a helpful description
        provider_choices.append(
            questionary.Choice(
                title="Customize (for other OpenAI-compatible APIs)", value="customize"
            )
        )

        provider_key = questionary.select(
            "Choose your LLM provider:",
            choices=provider_choices,
            use_indicator=True,
        ).ask()

        if not provider_key:
            print("[yellow]Setup cancelled. No provider selected.[/yellow]")
            return

        base_url = PROVIDER_CONFIGS[provider_key].base_url

        if not base_url:
            # å¦‚æœæ˜¯è‡ªå®šä¹‰æˆ–é¢„è®¾ä¸­æ²¡æœ‰ base_urlï¼Œåˆ™è¦æ±‚ç”¨æˆ·è¾“å…¥
            while True:
                base_url = questionary.text(
                    "Enter the Base URL for your provider:"
                ).ask()
                if not base_url:
                    print("[yellow]Base URL not provided. Setup cancelled.[/yellow]")
                    return
                # å³æ—¶éªŒè¯ URL
                if self._config_mgr.validate_url_input(base_url):
                    break
                else:
                    print(
                        "[bold red]Invalid URL. Please enter a valid HTTP/HTTPS URL.[/bold red]"
                    )

        api_key = questionary.password(
            "Enter API Key (can be optional for local models):"
        ).ask()

        llm_provider_instance: LLMProvider | None = get_provider_instance(
            provider_key, base_url, api_key
        )

        models: list[str] = []
        if llm_provider_instance:
            models = llm_provider_instance.fetch_models()
        else:
            print(
                "[bold red]Error: Could not initialize LLM provider. Cannot fetch models.[/bold red]"
            )

        model_name: str | None = None
        if models:
            model_name = questionary.select(
                "Select a default model to use:", choices=models, use_indicator=True
            ).ask()
        else:
            print(
                "\nâš ï¸ Could not fetch model list from the provided API. You may need to manually enter the model name."
            )
            model_name = questionary.text(
                "Please manually enter a default model name:"
            ).ask()

        if not model_name:
            print("[yellow]Model name not provided. Setup cancelled.[/yellow]")
            return

        # æ„å»ºè¦ä¿å­˜çš„é…ç½®æ•°æ®ç»“æ„ï¼Œç¡®ä¿ç¬¦åˆ Dynaconf çš„ç¯å¢ƒåµŒå¥—æ ¼å¼
        config_to_save: dict[str, Any] = {
            "default": {
                "model": {
                    "base_url": base_url,
                    "model_name": model_name,
                }
            }
        }
        secrets_to_save: dict[str, Any] = {
            "default": {
                "model": {
                    "api_key": api_key or "",
                }
            }
        }

        self._config_mgr.save_config(config_to_save, secrets_to_save)
        print("Please re-run your desired command with the new configuration.")
